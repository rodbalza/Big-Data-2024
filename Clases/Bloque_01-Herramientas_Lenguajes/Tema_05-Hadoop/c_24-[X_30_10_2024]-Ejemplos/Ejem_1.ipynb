{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuración de un Clúster HDFS en Docker y Operaciones Básicas en HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 0: Crear el directorio del proyecto. Si estas trabajando desde vs code con wsl es posible que al momento de crear los ficheros tengas problemas con los permisos. Normalmente la ruta desd wsl empieza por /mnt por lo que debemos movernos a home/usuario. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un directorio para el proyecto y navega a él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "mkdir /home/balrodjuan/hdfs-docker-cluster\n",
    "cd /home/balrodjuan/hdfs-docker-cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Crear la estructura de directorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta los siguientes comandos para crear la estructura de directorios necesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "mkdir -p hadoop_config\n",
    "mkdir hadoop_namenode hadoop_datanode1 hadoop_datanode2\n",
    "touch docker-compose.yml hadoop_config/core-site.xml hadoop_config/hdfs-site.xml hadoop_config/log4j.properties start-hdfs.sh init-datanode.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estructura deberia verse asi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "hdfs-docker-cluster/\n",
    "│\n",
    "├── docker-compose.yml\n",
    "├── hadoop_config/\n",
    "│   ├── core-site.xml\n",
    "│   ├── hdfs-site.xml\n",
    "│   ├── log4j.properties\n",
    "├── start-hdfs.sh\n",
    "├── init-datanode.sh\n",
    "├── hadoop_namenode/\n",
    "├── hadoop_datanode1/\n",
    "└── hadoop_datanode2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Configuración de Docker Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Abre el archivo `docker-compose.yml` y agrega el siguiente contenido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "services:\n",
    "  namenode:\n",
    "    image: apache/hadoop:3.3.5\n",
    "    container_name: namenode\n",
    "    hostname: namenode\n",
    "    user: root\n",
    "    environment:\n",
    "      - HADOOP_HOME=/opt/hadoop\n",
    "    volumes:\n",
    "      - ./hadoop_namenode:/opt/hadoop/data/nameNode\n",
    "      - ./hadoop_config:/opt/hadoop/etc/hadoop\n",
    "      - ./start-hdfs.sh:/start-hdfs.sh\n",
    "    ports:\n",
    "      - \"9870:9870\"\n",
    "    command: [ \"/bin/bash\", \"/start-hdfs.sh\" ]\n",
    "    networks:\n",
    "      hdfs_network:\n",
    "        ipv4_address: 172.20.0.2\n",
    "\n",
    "  datanode1:\n",
    "    image: apache/hadoop:3.3.5\n",
    "    container_name: datanode1\n",
    "    hostname: datanode1\n",
    "    user: root\n",
    "    environment:\n",
    "      - HADOOP_HOME=/opt/hadoop\n",
    "    volumes:\n",
    "      - ./hadoop_datanode1:/opt/hadoop/data/dataNode\n",
    "      - ./hadoop_config:/opt/hadoop/etc/hadoop\n",
    "      - ./init-datanode.sh:/init-datanode.sh\n",
    "    depends_on:\n",
    "      - namenode\n",
    "    command: [ \"/bin/bash\", \"/init-datanode.sh\" ]\n",
    "    networks:\n",
    "      hdfs_network:\n",
    "        ipv4_address: 172.20.0.3\n",
    "\n",
    "  datanode2:\n",
    "    image: apache/hadoop:3.3.5\n",
    "    container_name: datanode2\n",
    "    hostname: datanode2\n",
    "    user: root\n",
    "    environment:\n",
    "      - HADOOP_HOME=/opt/hadoop\n",
    "    volumes:\n",
    "      - ./hadoop_datanode2:/opt/hadoop/data/dataNode\n",
    "      - ./hadoop_config:/opt/hadoop/etc/hadoop\n",
    "      - ./init-datanode.sh:/init-datanode.sh\n",
    "    depends_on:\n",
    "      - namenode\n",
    "    command: [ \"/bin/bash\", \"/init-datanode.sh\" ]\n",
    "    networks:\n",
    "      hdfs_network:\n",
    "        ipv4_address: 172.20.0.4\n",
    "\n",
    "networks:\n",
    "  hdfs_network:\n",
    "    ipam:\n",
    "      driver: default\n",
    "      config:\n",
    "        - subnet: 172.20.0.0/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Crear los scripts de inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script `start-hdfs.sh` para el NameNode. Agrega el siguiente contenido al archivo `start-hdfs.sh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "if [ ! -d \"/opt/hadoop/data/nameNode/current\" ]; then\n",
    "    echo \"Formatting NameNode...\"\n",
    "    hdfs namenode -format\n",
    "fi\n",
    "hdfs namenode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script `init-datanode.sh` para los DataNodes. agrega el siguiente contenido al archivo `init-datanode.sh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "rm -rf /opt/hadoop/data/dataNode/*\n",
    "chown -R hadoop:hadoop /opt/hadoop/data/dataNode\n",
    "chmod 755 /opt/hadoop/data/dataNode\n",
    "hdfs datanode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dar permisos de ejecución a los scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "chmod +x start-hdfs.sh\n",
    "chmod +x init-datanode.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Configuración de los archivos de Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuración de `core-site.xml`. Agrega el siguiente contenido al archivo `core-site.xml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "<configuration>\n",
    "  <property>\n",
    "    <name>fs.defaultFS</name>\n",
    "    <value>hdfs://namenode:8020</value>\n",
    "  </property>\n",
    "</configuration>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuración de `hdfs-site.xml`. Agrega el siguiente contenido al archivo `hdfs-site.xml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "<configuration>\n",
    "  <property>\n",
    "    <name>dfs.replication</name>\n",
    "    <value>2</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.namenode.name.dir</name>\n",
    "    <value>/opt/hadoop/data/nameNode</value>\n",
    "  </property>\n",
    "  <property>\n",
    "    <name>dfs.datanode.data.dir</name>\n",
    "    <value>/opt/hadoop/data/dataNode</value>\n",
    "  </property>\n",
    "</configuration>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Configuración de `log4j.properties`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar la advertencia de log4j, agrega la siguiente configuración básica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "log4j.rootLogger=INFO, console\n",
    "log4j.appender.console=org.apache.log4j.ConsoleAppender\n",
    "log4j.appender.console.target=System.err\n",
    "log4j.appender.console.layout=org.apache.log4j.PatternLayout\n",
    "log4j.appender.console.layout.ConversionPattern=%d{ISO8601} %-5p %c{2} - %m%n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6. Lanzar el clúster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicia el clúster de HDFS usando Docker Compose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica que los contenedores estén en funcionamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accede a la interfaz web del NameNode en: `http://localhost:9870`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 7. Operaciones Básicas en HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 Listar Directorios y Archivos en HDFS. Para ver el contenido de un directorio en HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker exec -it namenode hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 Subir Archivos a HDFS. Crear un archivo de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "echo \"Hello, HDFS\" > test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3 Copiar el archivo al contenedor `namenode`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker cp test.txt namenode:/tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.4 Subir el archivo a HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker exec -it namenode hdfs dfs -put /tmp/test.txt /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.5  Ver el Contenido de un Archivo en HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker exec -it namenode hdfs dfs -cat /test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.6 Eliminar un Archivo o Directorio en HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker exec -it namenode hdfs dfs -rm /test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.7 Eliminar un directorio y su contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker exec -it namenode hdfs dfs -rm -r /ruta/en/hdfs/directorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.8 Crear un Directorio en HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker exec -it namenode hdfs dfs -mkdir /ruta/en/hdfs/nuevo_directorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://bytemedirk.medium.com/setting-up-an-hdfs-cluster-with-docker-compose-a-step-by-step-guide-4541cd15b168"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 2 Configuración de un clúster HDFS con Docker Compose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ingeniero de datos, siempre me ha fascinado el poder de los sistemas distribuidos. Recientemente, me embarqué en un viaje para configurar un clúster Hadoop Distributed File System (HDFS) utilizando Docker Compose. Este artículo comparte mi experiencia y proporciona una guía paso a paso para aquellos que buscan replicar esta configuración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Por qué Docker Compose para HDFS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker Compose ofrece una forma cómoda de definir y ejecutar aplicaciones Docker multicontenedor. Para un clúster HDFS, que consta de varios nodos (NameNode y DataNodes), Docker Compose proporciona una solución ideal para crear un entorno reproducible y fácil de gestionar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro cluster HDFS consistirá en un NameNode y dos DataNodes. Esto es lo que necesitarás:  \n",
    "\n",
    "1. Docker y Docker Compose instalados en su sistema\n",
    "2. Basic understanding of HDFS and Docker concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Estructura del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, cree una estructura de directorios para su proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "hdfs-docker-cluster/\n",
    "│\n",
    "├── docker-compose.yml\n",
    "├── hadoop_config/\n",
    "│   ├── core-site.xml\n",
    "│   ├── hdfs-site.xml\n",
    "│   └── ... (other Hadoop configuration files)\n",
    "├── start-hdfs.sh\n",
    "├── init-datanode.sh\n",
    "├── hadoop_namenode/\n",
    "├── hadoop_datanode1/\n",
    "└── hadoop_datanode2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "mkdir -p hdfs-docker-cluster/hadoop_config hdfs-docker-cluster/hadoop_namenode hdfs-docker-cluster/hadoop_datanode1 hdfs-docker-cluster/hadoop_datanode2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "1.1 Navega al directorio principal del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd hdfs-docker-cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Crea los archivos necesarios dentro de hdfs-docker-cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "touch docker-compose.yml start-hdfs.sh init-datanode.sh\n",
    "touch hadoop_config/core-site.xml hadoop_config/hdfs-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Configuración del Docker Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cree un archivo `docker-compose.yml` con el siguiente contenido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# yml\n",
    "version: '3'\n",
    "\n",
    "services:\n",
    "  namenode:\n",
    "    image: apache/hadoop:3.3.5\n",
    "    container_name: namenode\n",
    "    hostname: namenode\n",
    "    user: root\n",
    "    environment:\n",
    "      - HADOOP_HOME=/opt/hadoop\n",
    "    volumes:\n",
    "      - ./hadoop_namenode:/opt/hadoop/data/nameNode\n",
    "      - ./hadoop_config:/opt/hadoop/etc/hadoop\n",
    "      - ./start-hdfs.sh:/start-hdfs.sh\n",
    "    ports:\n",
    "      - \"9870:9870\"\n",
    "    command: [ \"/bin/bash\", \"/start-hdfs.sh\" ]\n",
    "    networks:\n",
    "      hdfs_network:\n",
    "        ipv4_address: 172.20.0.2\n",
    "\n",
    "  datanode1:\n",
    "    image: apache/hadoop:3.3.5\n",
    "    container_name: datanode1\n",
    "    hostname: datanode1\n",
    "    user: root\n",
    "    environment:\n",
    "      - HADOOP_HOME=/opt/hadoop\n",
    "    volumes:\n",
    "      - ./hadoop_datanode1:/opt/hadoop/data/dataNode\n",
    "      - ./hadoop_config:/opt/hadoop/etc/hadoop\n",
    "      - ./init-datanode.sh:/init-datanode.sh\n",
    "    depends_on:\n",
    "      - namenode\n",
    "    command: [ \"/bin/bash\", \"/init-datanode.sh\" ]\n",
    "    networks:\n",
    "      hdfs_network:\n",
    "        ipv4_address: 172.20.0.3\n",
    "\n",
    "  datanode2:\n",
    "    # Similar configuration to datanode1, with different container_name and IP\n",
    "\n",
    "networks:\n",
    "  hdfs_network:\n",
    "    ipam:\n",
    "      driver: default\n",
    "      config:\n",
    "        - subnet: 172.20.0.0/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Inicializar scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear dos scripts para inicializar el NameNode y el DataNode:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`start-hdfs.sh` for the NameNode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "if [ ! -d \"/opt/hadoop/data/nameNode/current\" ]; then\n",
    "    echo \"Formatting NameNode...\"\n",
    "    hdfs namenode -format\n",
    "fi\n",
    "hdfs namenode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`init-datanode.sh` for the DataNodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "rm -rf /opt/hadoop/data/dataNode/*\n",
    "chown -R hadoop:hadoop /opt/hadoop/data/dataNode\n",
    "chmod 755 /opt/hadoop/data/dataNode\n",
    "hdfs datanode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Configuración de Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el directorio `hadoop_config/`, coloque sus archivos de configuración de Hadoop. Los archivos clave son core-site.xml y hdfs-site.xml. Asegúrese de que están configurados correctamente para su clúster HDFS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Lanzar el cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que los contenedores estén en funcionamiento, puede verificar la funcionalidad del clúster:  \n",
    "1. Accede a la interfaz web de NameNode en `http://localhost:9870`  \n",
    "2. Use HDFS commands through the NameNode container: `docker exec -it namenode hdfs dfs -ls /`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker exec -it namenode hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añade un archivo a HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "echo \"Hello, HDFS\" > test.txt\n",
    "docker cp test.txt namenode:/tmp/\n",
    "docker exec -it namenode hdfs dfs -put /tmp/test.txt /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver el archivo en HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker exec -it namenode hdfs dfs -cat /test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puede consultar el estado del clúster en la interfaz web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1](1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí podemos ver nuestros dos datanodes, y también el histograma de uso de los procesos que hemos probado.  \n",
    "Incluso podemos echar un vistazo a los archivos que hemos creado y movido en el directorio browse del servidor web:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2](2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
